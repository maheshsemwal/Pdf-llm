# Pdf-llm

This project is a full-stack application for PDF processing and question-answering using AI technologies. It consists of a Python backend API and a React frontend interface.

## ğŸ—ï¸ Project Structure

```
pdf-llm/
â”œâ”€â”€ backend/                 # Python Flask/FastAPI backend
â”‚   â”œâ”€â”€ main.py             # Main application entry point
â”‚   â”œâ”€â”€ clients/            # External service clients
â”‚   â”‚   â”œâ”€â”€ pinecone_client.py
â”‚   â”‚   â””â”€â”€ supabase_client.py
â”‚   â”œâ”€â”€ routes/             # API route handlers
â”‚   â”‚   â”œâ”€â”€ ask_question.py
â”‚   â”‚   â”œâ”€â”€ pdf_routes.py
â”‚   â”‚   â””â”€â”€ process.py
â”‚   â””â”€â”€ services/           # Business logic services
â”‚       â”œâ”€â”€ downloader.py
â”‚       â”œâ”€â”€ embedder.py
â”‚       â”œâ”€â”€ extractor.py
â”‚       â”œâ”€â”€ llama_query.py
â”‚       â”œâ”€â”€ pdf_service.py
â”‚       â””â”€â”€ processor.py
â””â”€â”€ frontend/               # React frontend application
    â”œâ”€â”€ src/
    â”œâ”€â”€ public/
    â””â”€â”€ package.json
```

## ğŸš€ Features

- **PDF Processing**: Upload and process PDF documents
- **AI-Powered Q&A**: Ask questions about uploaded documents
- **Vector Storage**: Efficient document embedding and retrieval
- **Modern UI**: React-based frontend with TypeScript support

## ğŸ§  AI Question Answering Capabilities

The system now supports **Hybrid AI Responses** that intelligently combine document-specific information with general knowledge:

### Question Types Supported:

1. **Document-Specific Questions**: 
   - "What does this document say about X?"
   - "Summarize this PDF"
   - "According to this document..."
   
2. **General Knowledge Questions**:
   - "What is artificial intelligence?"
   - "How does machine learning work?"
   - "Explain neural networks"

3. **Hybrid Questions** (Document + General Knowledge):
   - "How does this approach compare to industry standards?"
   - "What are the implications of these findings?"
   - "Can you explain the concepts mentioned here?"

### How It Works:

- **Smart Classification**: The system automatically classifies questions to determine the best response approach
- **Context Retrieval**: Retrieves relevant chunks from the uploaded PDF using vector similarity search  
- **Intelligent Prompting**: Creates tailored prompts based on question type and available context
- **Fallback Handling**: Gracefully handles cases where PDF content isn't relevant to the question
- **Source Attribution**: Clearly indicates whether information comes from the document or general knowledge

This ensures users get comprehensive, accurate answers whether they're asking about their specific document or seeking general information.

## ğŸ› ï¸ Technologies Used

### Backend
- **Python** - Core programming language
- **Pinecone** - Vector database for embeddings
- **Supabase** - Database and backend services
- **LLaMA** - Large language model for question answering

### Frontend
- **React** - Frontend framework
- **TypeScript** - Type-safe JavaScript
- **Vite** - Build tool and development server

## ğŸ›ï¸ System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   React Frontendâ”‚    â”‚  FastAPI Backendâ”‚    â”‚  External APIs  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  - TypeScript   â”‚â—„â”€â”€â–ºâ”‚  - Python       â”‚â—„â”€â”€â–ºâ”‚  - Supabase DB  â”‚
â”‚  - Vite         â”‚    â”‚  - FastAPI      â”‚    â”‚  - Pinecone VDB â”‚
â”‚  - Tailwind CSS â”‚    â”‚  - Uvicorn      â”‚    â”‚  - Groq/LLaMA   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Architecture

```
Frontend (React/TypeScript)
â”œâ”€â”€ Components
â”‚   â”œâ”€â”€ ChatInterface       # Main chat UI
â”‚   â”œâ”€â”€ PDFUpload          # File upload component
â”‚   â”œâ”€â”€ ThemeProvider      # Dark/Light mode
â”‚   â””â”€â”€ UI Components      # Reusable UI elements
â”œâ”€â”€ Services
â”‚   â”œâ”€â”€ API Client         # Backend communication
â”‚   â””â”€â”€ User Service       # User session management
â””â”€â”€ State Management       # React state and context

Backend (FastAPI/Python)
â”œâ”€â”€ Routes
â”‚   â”œâ”€â”€ PDF Routes         # File upload/processing
â”‚   â”œâ”€â”€ Chat Routes        # Chat management
â”‚   â”œâ”€â”€ Question Routes    # Q&A endpoints
â”‚   â””â”€â”€ Process Routes     # PDF processing pipeline
â”œâ”€â”€ Services
â”‚   â”œâ”€â”€ PDF Service        # PDF handling and storage
â”‚   â”œâ”€â”€ Embedder Service   # Text embedding generation
â”‚   â”œâ”€â”€ LLaMA Query        # AI question answering
â”‚   â”œâ”€â”€ Extractor Service  # Text extraction from PDFs
â”‚   â””â”€â”€ Processor Service  # Orchestrates PDF processing
â”œâ”€â”€ Clients
â”‚   â”œâ”€â”€ Supabase Client    # Database operations
â”‚   â””â”€â”€ Pinecone Client    # Vector database operations
â””â”€â”€ Models                 # Pydantic data models

External Services
â”œâ”€â”€ Supabase
â”‚   â”œâ”€â”€ PostgreSQL DB     # Relational data (chats, messages)
â”‚   â””â”€â”€ Storage Bucket    # PDF file storage
â”œâ”€â”€ Pinecone Vector DB    # Document embeddings
â””â”€â”€ Groq/LLaMA API       # Large Language Model
```

### Data Flow

1. **PDF Upload & Processing**:
   ```
   User uploads PDF â†’ FastAPI receives file â†’ Store in Supabase Storage
   â†’ Extract text â†’ Generate embeddings â†’ Store in Pinecone â†’ Return file_id
   ```

2. **Chat Creation**:
   ```
   Frontend creates chat â†’ Store chat metadata in Supabase
   â†’ Associate with PDF file_id â†’ Return chat_id
   ```

3. **Question Answering**:
   ```
   User asks question â†’ Store message in DB â†’ Query Pinecone for relevant context
   â†’ Send context + question to LLaMA â†’ Generate answer â†’ Store assistant response
   â†’ Return answer to frontend
   ```

4. **Chat Management**:
   ```
   Frontend requests chat history â†’ Query Supabase for chats/messages
   â†’ Return formatted chat data â†’ Display in UI
   ```

### Technology Stack Flow

```
React Frontend â”€â”€HTTP/RESTâ”€â”€â–º FastAPI Backend
                                    â”‚
                                    â”œâ”€â”€â–º Supabase (PostgreSQL)
                                    â”‚    â”œâ”€â”€ chats table
                                    â”‚    â”œâ”€â”€ messages table
                                    â”‚    â””â”€â”€ storage bucket
                                    â”‚
                                    â”œâ”€â”€â–º Pinecone Vector DB
                                    â”‚    â””â”€â”€ document embeddings
                                    â”‚
                                    â””â”€â”€â–º Groq/LLaMA API
                                         â””â”€â”€ text generation
```

## ğŸ“‹ Prerequisites

- Python 3.8+
- Node.js 16+
- npm or yarn

## ğŸ”§ Installation

### Backend Setup

1. Navigate to the backend directory:
   ```bash
   cd backend
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   ```

3. Activate the virtual environment:
   - Windows: `venv\Scripts\activate`
   - macOS/Linux: `source venv/bin/activate`

4. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

5. Set up environment variables:
   - Create a `.env` file in the backend directory
   - Add your API keys and configuration

6. Run the backend server:
   ```bash
   python main.py
   ```

### Frontend Setup

1. Navigate to the frontend directory:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Start the development server:
   ```bash
   npm run dev
   ```

## ğŸ”‘ Environment Variables

Create a `.env` file in the backend directory with the following variables:

```env
PINECONE_API_KEY=your_pinecone_api_key
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key
LLAMA_API_KEY=your_llama_api_key
```

## ğŸ“š API Endpoints

### PDF Management

#### Upload PDF
- **POST** `/pdf-upload`
- **Description**: Upload a PDF file to Supabase storage
- **Headers**: 
  - `X-User-ID` (optional): User identifier
- **Body**: Multipart form data
  - `file`: PDF file (required)
- **Response**: Upload confirmation with file details

### Question & Answer

#### Ask Question
- **POST** `/ask-question`
- **Description**: Ask a question about a specific PDF file using AI
- **Body**:
```json
{
  "file_id": "unique-file-id",
  "question": "What is the main topic of this document?"
}
```
- **Response**:
```json
{
  "answer": "The main topic of this document is..."
}
```

### Chat Management

#### Create Chat
- **POST** `/chat/create`
- **Description**: Create a new chat session when PDF is uploaded
- **Body**:
```json
{
  "title": "Chat about Document Title",
  "pdf_document_id": "document-id",
  "file_id": "unique-file-id",
  "user_id": "user-123" // optional
}
```
- **Response**:
```json
{
  "id": "chat-id",
  "title": "Chat about Document Title",
  "pdf_document_id": "document-id",
  "file_id": "unique-file-id",
  "user_id": "user-123",
  "created_at": "2025-06-24T10:30:00Z",
  "updated_at": "2025-06-24T10:30:00Z"
}
```

#### Send Message
- **POST** `/chat/message`
- **Description**: Store a message in the database
- **Body**:
```json
{
  "chat_id": "chat-id",
  "content": "Hello, what is this document about?",
  "sender": "user" // "user" or "assistant"
}
```
- **Response**:
```json
{
  "id": "message-id",
  "chat_id": "chat-id",
  "content": "Hello, what is this document about?",
  "sender": "user",
  "created_at": "2025-06-24T10:35:00Z"
}
```

#### Get All Chats
- **GET** `/chat/all`
- **Description**: Get all chats (for when user_id is empty)
- **Response**:
```json
[
  {
    "id": "chat-id",
    "title": "Chat about Document Title",
    "pdf_document_id": "document-id",
    "file_id": "unique-file-id",
    "user_id": "user-123",
    "created_at": "2025-06-24T10:30:00Z",
    "updated_at": "2025-06-24T10:30:00Z"
  }
]
```

#### Get User Chats
- **GET** `/chat/user/{user_id}/chats`
- **Description**: Get all chats for a specific user
- **Parameters**:
  - `user_id` (path): User identifier
- **Response**: Array of chat objects (same format as above)

#### Get Chat with Messages
- **GET** `/chat/{chat_id}`
- **Description**: Fetch a chat with all its messages
- **Parameters**:
  - `chat_id` (path): Chat identifier
- **Response**:
```json
{
  "chat": {
    "id": "chat-id",
    "title": "Chat about Document Title",
    "pdf_document_id": "document-id",
    "file_id": "unique-file-id",
    "user_id": "user-123",
    "created_at": "2025-06-24T10:30:00Z",
    "updated_at": "2025-06-24T10:30:00Z"
  },
  "messages": [
    {
      "id": "message-id",
      "chat_id": "chat-id",
      "content": "Hello, what is this document about?",
      "sender": "user",
      "created_at": "2025-06-24T10:35:00Z"
    }
  ]
}
```

#### Delete Chat
- **DELETE** `/chat/{chat_id}`
- **Description**: Delete a chat and all its messages
- **Parameters**:
  - `chat_id` (path): Chat identifier
- **Response**:
```json
{
  "message": "Chat deleted successfully"
}
```

### General

#### Health Check
- **GET** `/`
- **Description**: Basic health check endpoint
- **Response**:
```json
{
  "Hello": "World"
}
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

If you encounter any issues or have questions, please open an issue on the GitHub repository.

---

